# Adaptable Prompt Template for Large Language Models (LLMs)

## 1. Context and Task Definition
- Clearly define the context of the task
- Specify the main objective and any sub-tasks
- Include any relevant background information
- If applicable, mention the specific LLM being used (e.g., GPT-3, Claude, etc.)
- State the current date and any relevant time-sensitive information
- Clarify the LLM's knowledge cutoff date and how to handle information beyond that date
- For tasks involving specific domains, provide relevant domain knowledge or context

## 2. Input Data
- Describe the input data or information provided
- Specify any formatting requirements or constraints
- If using external sources, clearly indicate how they should be referenced
- For tasks involving images or other non-text inputs, provide clear instructions on how to describe or reference them
- If the task involves analyzing long texts, consider breaking them into smaller, manageable chunks
- Clarify how to handle any ambiguities or inconsistencies in the input data
- For tasks involving URLs, links, or videos, instruct the LLM to ask the user to paste the relevant text or image content directly into the conversation

## 3. Instructions
- Provide clear, step-by-step instructions for the LLM
- Use imperative language and be specific about actions required
- Break down complex tasks into smaller, manageable steps
- For multi-step tasks, consider using a least-to-most prompting approach:
  a. Prompt the LLM to identify subtasks: "To solve {question}, we need to first solve: "
  b. Solve each subtask sequentially, building on previous solutions
- For tasks requiring code generation, specify the programming language and any specific libraries or frameworks to use
- When appropriate, instruct the LLM to think through problems step-by-step before giving a final answer
- For tasks involving math or logic, explicitly ask the LLM to show its work
- For tasks involving expression of views held by a significant number of people, instruct the LLM to provide assistance regardless of its own views

## 4. Reasoning Prompts
- Incorporate prompts that encourage step-by-step reasoning
- Use phrases like "Let's think step by step" or "First, let's consider..."
- For complex tasks, use selection-inference prompting:
  a. Selection: "From the given information, select the relevant facts for this step"
  b. Inference: "Based on these selected facts, what can we infer?"
- For tasks requiring longer reasoning chains, consider implementing a loop:
  a. Selection prompt
  b. Inference prompt
  c. Halting prompt: "Are these inferences sufficient to answer the question? If not, what additional information do we need?"
- For mathematical or logical problems, encourage the LLM to show its work and explain each step
- Consider using the faithful reasoning architecture for complex reasoning tasks:
  a. Implement a 'halter' model to determine when to stop the reasoning process
  b. Use a value function to assess the quality of reasoning steps and search over multiple trajectories
- For tasks involving multiple possible approaches, consider using maieutic prompting to generate and evaluate multiple reasoning paths

## 5. Output Format
- Clearly specify the desired output format
- Provide examples if necessary
- Include any required headings, sections, or structural elements
- For code or specific formats, use appropriate syntax highlighting or markdown
- If generating HTML or other renderable content, specify any restrictions (e.g., no external scripts, use of placeholder images)
- For tasks that may require substantial content, consider using artifacts and provide instructions on how to format them
- Specify any requirements for citations or references in the output
- For tasks involving SVG generation, instruct the LLM to specify the viewbox rather than defining width/height

## 6. Evaluation Criteria
- Define how the output will be evaluated or judged
- Specify any metrics or benchmarks to be met
- Include self-evaluation prompts: "Review your response. Does it fully address the task and meet all specified criteria?"
- For tasks with multiple possible answers, instruct the LLM to generate and evaluate multiple solutions
- Consider implementing a separate verifier model or function for critical tasks
- If applicable, instruct the LLM to provide a confidence score for its output

## 7. Constraints and Limitations
- Mention any constraints or limitations the LLM should consider
- Specify any topics, language, or content to avoid
- Provide guidelines for handling uncertainty or incomplete information
- Clarify any limitations of the LLM (e.g., inability to access external websites or databases)
- Instruct the LLM to clearly state when it cannot perform a task without apologizing
- Specify any time or computational constraints that may affect the task
- Remind the LLM that it cannot open URLs, links, or videos

## 8. Examples (Optional)
- Provide examples of good responses or outputs
- Include both positive and negative examples if helpful
- For few-shot learning, ensure examples are diverse and representative
- If using chain-of-thought prompting, include examples that demonstrate the reasoning process
- Consider using the STaR (Self-taught Reasoner) technique to generate a dataset of explanations for fine-tuning
- Ensure examples cover a range of difficulty levels and edge cases

## 9. Verification and Iteration
- Ask the LLM to verify its output against the given criteria
- Encourage self-correction and refinement of the response
- Implement a self-consistency check:
  a. Generate multiple responses (e.g., 3-5) for the same prompt
  b. Compare the responses and identify the most consistent or highest quality answer
  c. Refine the chosen answer if necessary
- For critical tasks, consider implementing a separate verifier model or function
- If the task is very long and cannot be completed in a single response, offer to do it piecemeal and get feedback from the user as each part is completed
- Instruct the LLM to flag any parts of its response it's uncertain about

## 10. Adaptability Instructions
- Provide guidance on how to adapt this template for different tasks or domains
- Suggest areas where customization might be beneficial
- Include instructions for fine-tuning or specializing the template for specific use cases
- Explain how to modify the template for different model sizes or capabilities
- Encourage users to experiment with customizing the instruction wording for their specific use case
- Provide guidelines for adapting the prompt based on the LLM's performance on similar tasks

## 11. Error Handling and Edge Cases
- Provide instructions for handling potential errors or unexpected inputs
- Ask the LLM to consider edge cases and how to address them
- Include a prompt for generating alternative approaches if the primary method fails
- Instruct the LLM to clearly indicate when it encounters limitations or cannot complete a task
- For tasks involving code, instruct the LLM to handle potential errors and provide error messages
- Guide the LLM on how to proceed if it encounters conflicting or ambiguous information

## 12. Ethical Considerations
- Remind the LLM to consider ethical implications of its outputs
- Provide guidelines for handling sensitive or controversial topics
- Instruct the LLM to flag any potentially harmful or biased content
- Encourage the LLM to maintain objectivity and avoid expressing personal opinions on controversial topics
- Instruct the LLM not to produce content that would be highly hazardous to human health or wellbeing if misused
- Guide the LLM to consider diverse perspectives and avoid reinforcing stereotypes
- Instruct the LLM to provide careful thoughts and clear information on controversial topics, without explicitly saying the topic is sensitive or claiming to present objective facts

## 13. Confidence and Uncertainty
- Ask the LLM to provide a confidence level for its responses when appropriate
- Instruct the LLM to clearly indicate when it's unsure or when information is speculative
- For complex tasks, consider implementing a probabilistic approach:
  a. Generate a tree of possible explanations
  b. Assess the model's belief in each explanation
  c. Identify logical relationships (entailment, contradiction) between explanations
  d. Use a weighted maximum satisfiability problem (MAX-SAT) to find the most consistent set of beliefs
- Encourage the LLM to express uncertainty about very obscure topics and remind users about the possibility of hallucination
- Instruct the LLM to clarify when it's extrapolating beyond its training data
- Guide the LLM on how to handle conflicting information or inconsistencies in its knowledge base
- For very obscure topics, instruct the LLM to remind the user about the possibility of hallucination, using the term 'hallucinate'
- When mentioning or citing particular articles, papers, or books, instruct the LLM to remind the user that it doesn't have access to search or a database and may hallucinate citations

## 14. Feedback and Improvement
- Include instructions for users to provide feedback on the LLM's performance
- Suggest ways for users to report issues or inaccuracies
- Remind users that the LLM cannot retain or learn from the current conversation, but feedback can be provided to the developers
- If applicable, mention the option to use the 'thumbs down' button for providing feedback
- Encourage users to provide specific examples of good and bad outputs to help improve the system
- Clarify that while the LLM can't learn from the current conversation, it can offer to refine its responses based on immediate feedback

## 15. Interaction and Follow-up
- Encourage the LLM to ask for clarification if the task or input is ambiguous
- Instruct the LLM to offer elaboration on its responses if further information might be helpful
- For conversational tasks, guide the LLM to maintain context and refer back to previous interactions when appropriate
- Provide instructions for handling follow-up questions or requests for additional information
- Guide the LLM on how to suggest related topics or extensions of the current task when appropriate
- Instruct the LLM to be direct in its responses, avoiding unnecessary affirmations or filler phrases
- Instruct the LLM to avoid starting responses with the word "Certainly" in any way

## 16. Language and Tone
- Specify the desired language for the LLM's responses
- Provide guidelines on the appropriate tone and style for the task (e.g., formal, casual, technical)
- Instruct the LLM to adapt its language complexity to the user's level of expertise
- Guide the LLM on how to maintain consistency in terminology and phrasing throughout the interaction
- Instruct the LLM to respond in the language used or requested by the user

## 17. Task-Specific Considerations
- For tasks involving code:
  - Specify how to handle code explanations (e.g., explain after closing code markdown)
  - Provide guidelines on commenting and documenting code
- For tasks involving mathematics:
  - Instruct the LLM on how to present mathematical notation or equations
  - Specify whether step-by-step solutions are required
- For tasks involving creative writing:
  - Provide guidelines on style, genre, and any specific literary techniques to use or avoid
- For analytical tasks:
  - Specify the level of detail required in the analysis
  - Guide the LLM on how to present and structure analytical findings
- For tasks involving image analysis:
  - Instruct the LLM to always respond as if it is completely face blind
  - Guide the LLM to never identify or name humans in images, nor imply recognition based on facial features
  - Instruct the LLM to describe images as someone would if they were unable to recognize any humans from images

---

Remember to customize this template based on your specific task and requirements. Adapt the sections as needed, and provide clear, concise instructions to guide the LLM in generating the desired output. For optimal performance, consider fine-tuning a custom model on your specific use case using techniques like STaR (Self-taught Reasoner) to bootstrap a dataset of explanations.

When using this template, be mindful of the specific capabilities and limitations of the LLM you're working with. Some advanced techniques may require fine-tuning or may only be applicable to certain model architectures. Always test and iterate on your prompts to achieve the best results for your particular use case.

This template is designed to be comprehensive and adaptable. Feel free to remove or modify sections that are not relevant to your specific task or LLM. The goal is to provide a structured approach to prompting that can be tailored to a wide range of applications while incorporating best practices for improving reliability and performance.

Remember that prompt engineering is an iterative process. Continuously refine your prompts based on the LLM's outputs and user feedback to achieve optimal results.

--------------------------------------------------------------------------------

# Streamlined Adaptable Prompt Template for Large Language Models

## 1. System Message (Optional)
System Message: Consider using a system message to set the initial context, behavior, or persona for the model. This is especially useful for maintaining consistent behavior across multiple interactions. For example:
```
SYSTEM: You are an AI assistant specialized in data analysis. Provide concise, accurate responses with a focus on statistical insights.
```

## 2. Context and Task Definition
Context: Providing clear context and task definition helps the model understand the background and specific requirements of the task. This reduces ambiguity and increases the likelihood of getting relevant and accurate responses. Include relevant background information here.

Task: Clearly define the specific task or question to be addressed. A well-defined task guides the model towards providing a focused and relevant response.

## 3. Desired Output Format
Output Format: Specify the desired format for the response (e.g., paragraph, list, JSON). This ensures that the model's response is structured in a way that's most useful for your needs, making it easier to process or present the information.

## 4. Role or Persona (Optional)
Role: If applicable, define a specific role or persona for the model to adopt. This can help tailor the model's responses to a particular style, expertise level, or perspective, which is particularly useful for tasks that require a specific tone or viewpoint. If you specify a persona, ensure that you maintain consistency throughout the interaction to avoid confusion.

Note: If you've used a system message to define a persona, ensure that your prompts align with and reinforce this persona throughout the interaction.

## 5. Instructions and Constraints
Instructions: Provide clear, step-by-step instructions for completing the task. Include any specific techniques or approaches to be used, as well as any constraints or limitations. Detailed instructions guide the model towards the desired output and help prevent misunderstandings or irrelevant responses.

1. [First instruction]
2. [Second instruction]
3. [Additional instructions as needed]

Constraints: [List any constraints or limitations here]

## 6. Input Data or Reference Material
Input Data: Include or reference any necessary input data or sources. Providing specific information or context helps ground the model's responses in relevant facts, reducing the likelihood of generating incorrect or irrelevant content.

## 7. Examples (Optional)
Examples: Including sample input-output pairs can clarify expectations and guide the model towards producing similar outputs for new inputs. This is particularly helpful for complex or nuanced tasks. This approach, known as "few-shot" prompting, can be especially effective when it's difficult to articulate explicit rules for the desired behavior.

Input: [Provide an example input]
Output: [Provide the corresponding desired output]

## 8. Evaluation Criteria (Optional)
Evaluation Criteria: Specify how the output will be evaluated or judged. This helps the model understand the key aspects to focus on, potentially improving the quality and relevance of its responses. Clear criteria can also be useful for assessing the model's performance.

## 9. Output Length (Optional)
Desired Output Length: Indicate the preferred length of the output (e.g., number of words, paragraphs). This helps control the level of detail in the model's response, ensuring it's neither too brief nor too verbose for your needs.

## 10. Breakdown for Complex Tasks
Subtasks: For complex tasks, break them down into smaller, manageable subtasks. This helps the model approach the problem more systematically, potentially improving accuracy and completeness of the response.

1. [First subtask]
2. [Second subtask]
3. [Additional subtasks as needed]

## 11. Reasoning and Explanation Requirements
Reasoning: Specify if step-by-step reasoning or explanations are required. This encourages the model to show its work, which can be useful for verifying the logic behind its responses or for educational purposes. Consider asking for a "chain of thought" before the final answer, as this can help the model reason its way toward correct answers more reliably, especially for complex problems.

## 12. Tool Usage (Optional)
Tools: Indicate any external tools or functions to be used. This can help the model leverage additional capabilities, such as performing calculations or accessing specific information, enhancing its ability to complete complex tasks. Note that the model cannot browse the internet or access real-time information unless specifically provided with such capabilities.

## 13. Rubric for Self-Evaluation (Optional)
Self-Evaluation Rubric: Provide criteria for the model to evaluate its own output. This encourages more thoughtful and accurate responses, as the model attempts to meet the specified standards. It can also help in identifying potential issues or areas for improvement.

- [Criterion 1]
- [Criterion 2]
- [Additional criteria as needed]

## 14. Specific Scenario or Use Case
Specific Use Case: Describe the specific scenario or use case for this prompt. This helps contextualize the task and can lead to more relevant and tailored responses from the model, as it better understands the real-world application of its output.

## 15. Delimiters
Delimiters: Specify any delimiters to be used for distinct parts of the input. Using delimiters helps clearly demarcate different sections of the input, making it easier for the model to distinguish between different types of information or instructions. This is particularly useful for complex prompts with multiple components. Examples of delimiters include:

- Triple quotes: """text"""
- XML-style tags: <tag>text</tag>
- Markdown headers: # Section Title
- Dashes or asterisks for bullet points: - point or * point

## 16. Inner Monologue (Optional)
Inner Monologue: If needed, provide instructions for using inner monologue (e.g., "Use <thinking> tags for your internal reasoning process"). This can be useful when you want the model to reason through a problem without immediately presenting its full thought process, which is helpful in educational contexts or when controlling information flow to the user.

## 17. Intent Classification (for Complex Multi-part Tasks)
Intent Classification: For complex multi-part tasks, provide categories for intent classification. This helps determine which instructions are most relevant based on the type of query, making your prompt more adaptable to a variety of user inputs within a single system.

## 18. Code Execution (Optional)
Code Execution: Indicate if code execution is required and provide necessary context. This allows the model to perform accurate calculations or interact with external APIs when necessary, which is particularly useful for tasks involving complex computations or data processing beyond the model's built-in capabilities.

## 19. Handling Long Inputs
Handling Long Inputs: For very long documents or conversations that exceed the model's context length, consider using piecewise summarization. Summarize sections of the document separately, then recursively summarize these summaries until you have a complete overview. This technique can be particularly useful for tasks involving lengthy texts or extended dialogues.

For multi-turn conversations, consider summarizing previous turns or selecting the most relevant parts to maintain context without exceeding token limits.

## 20. Advanced Techniques
Chaining Prompts: For complex tasks that exceed token limits or require multiple stages of processing, consider chaining multiple prompts. Each prompt in the chain can focus on a specific subtask, with the output of one prompt serving as input to the next.

Error Handling: Anticipate potential errors or unexpected outputs. Include instructions on how the model should behave if it encounters difficulties or if the input is ambiguous. For example: "If you're unsure about any part of the task, please state your uncertainty and explain why."

## 21. Performance Metrics
Defining Metrics: Clearly define the performance metrics by which you'll evaluate the effectiveness of your prompts. These could include accuracy, relevance, coherence, or task-specific metrics. Having clear metrics will guide your prompt refinement process and help in systematic testing.

## Final Notes on Clear Instructions
Throughout this prompt, strive for maximum clarity in your instructions. The model can't read your mind, so be explicit about what you want. If you need brief replies, ask for them. If you want expert-level writing, specify that. If you dislike a particular format, demonstrate the format you'd prefer. The clearer and more specific your instructions, the more likely you are to get the desired output.

Remember that the art of prompt engineering often lies in finding the right balance between providing clear, detailed instructions and allowing the model some flexibility to leverage its capabilities. Overly rigid prompts may constrain the model's performance, while overly vague prompts may lead to irrelevant or inaccurate outputs.

## Final Prompt Structure

[Use the sections above to construct your final prompt, removing or modifying sections as necessary for your specific task. Ensure that the flow of information is logical and that all necessary context and instructions are provided. Remember to be as clear and specific as possible in your instructions.]

When constructing your final prompt, consider the following:
1. Consistency with any defined persona or system messag

--------------------------------------------------------------------------------

# Enhanced Integrated LLM Prompting Template

[Note: This template is designed to be highly customizable. Modify, add, or remove sections as needed for your specific task or domain.]

## 1. Context and Goal
[Provide a brief description of the task or problem to be solved]

## 2. Similar Task Retrieval (Auto-CoT)
[Retrieve and list 2-3 similar tasks or examples relevant to the current goal]

## 3. Prompt Refinement (APE)
Based on the context and similar tasks, suggest improvements to this prompt:
[LLM suggests refinements to the prompt]

## 4. Role and Expertise
You are an expert in [specific field or role]. Approach this task from the perspective of:
- Researcher 1: [expert 1]
- Researcher 2: [expert 2]
- Researcher 3: [expert 3]
- Decider: Synthesize insights from all researchers

## 5. Input Data and Knowledge Retrieval
[Include any relevant data or background information]
- Initial knowledge retrieval: [RAG: Retrieve relevant information from external sources]

## 6. Planning (ReWOO)
Before proceeding, create a comprehensive plan for approaching the task:
1. [Step 1]
2. [Step 2]
3. ...

## 7. Instructions
Please follow these steps, interleaving reasoning and actions (React approach):

1. Analyze the provided information
2. Generate multiple approaches or solutions (Tree of Thought)
3. Evaluate each approach
4. Select the best solution
5. Provide a detailed explanation of your reasoning

At each step:
- Think through your reasoning process
- Perform any necessary actions or calculations
- [FLARE] If confidence is low, retrieve additional information and reassess
- Consider multiple reasoning paths (ToT)
- {% if [condition] %}
    [Execute specific action or reasoning path]
  {% else %}
    [Execute alternative action or reasoning path]
  {% endif %}

Repeat this process iteratively if necessary, refining your approach based on new information or insights.

## 8. Specific Task Requirements and Rails
[List any specific requirements or constraints for the task]
Topical Rail: Stay focused on [specific topic]
Fact-checking Rail: Verify key claims against retrieved information

## 9. Output Format
Present your response in the following format:
1. Summary of understanding
2. Detailed solution steps (with reasoning and actions interleaved)
3. Rationale for each decision
4. Final recommendation or conclusion

If the task requires, you may also produce:
- Code snippets
- SVG graphics
- React components
- Other structured data or content

When creating substantial, self-contained content that might be reused or modified, present it as a distinct artifact with a clear identifier and type.

## 10. Tools and Resources
You have access to the following tools:
- [Tool 1]: [Brief description]
- [Tool 2]: [Brief description]
- Calculator: For mathematical calculations
- Knowledge Retrieval: To access additional information when needed
Use these tools when necessary, explaining your reasoning for tool usage.

## 11. Reasoning and Reflection
- Express uncertainty when appropriate and explain why
- After providing your initial solution, reflect on its validity and potential improvements
- Consider alternative perspectives and approaches
- Generate multiple responses to the task (Self-consistency)
- Compare and evaluate these responses
- Select the most consistent and reliable response
- Engage in verbal reflection to reinforce learning from this task

## 12. Additional Considerations
- Consider ethical implications of your solution
- Address potential limitations or edge cases
- Suggest areas for further research or investigation
- Be aware of your own limitations as an AI model
- If you mention or cite particular sources, remind the user that you may hallucinate citations and they should verify them

## 13. Quality Assurance
Before finalizing your response:
- Review your solution for logical consistency
- Ensure all task requirements have been addressed
- Verify that your explanation is clear and comprehensive
- Check that you've stayed within the specified rails
- Confirm that any created content (code, graphics, etc.) is properly formatted and relevant

## 14. Chaining and Next Steps
- Indicate if this output should feed into another process or if additional steps are needed
- Consider how this response might fit into a larger workflow or system
- Suggest potential follow-up tasks or analyses that could build on this output
- If this is part of a chain, summarize key information to pass to the next step

Remember to maintain a [specific tone or style] throughout your response.

--------------------------------------------------------------------------------

# Final Comprehensive LLM Prompt Template

## 0. Pre-Prompt Considerations (Meta)
- Have you clearly defined success criteria for your use case?
- Do you have specific ways to empirically test against these criteria?
- Consider using the prompt generator in the Anthropic Console for a first draft.
- Is prompt engineering the best approach, or should you consider finetuning?

## 1. Context and Task Definition
<context>
[Provide clear, contextual information about the task, including:
- What the task results will be used for
- What audience the output is meant for
- What workflow the task is a part of, and where this task belongs in that workflow
- The end goal of the task, or what a successful task completion looks like]
</context>

Your task is to [clearly and specifically state the primary objective or task for the LLM].

## 2. Input Data
<input_data>
[Provide any necessary input data, documents, or resources required for the task. For long contexts (200K+ tokens), place this near the top of the prompt, above your query and instructions.]
</input_data>

## 3. Instructions
Follow these steps to complete the task:
1. [Provide step-by-step instructions]
2. [Be very specific about what you want the LLM to do]
3. [Use numbered lists or bullet points for clarity]
[Add more steps as needed]

## 4. Examples (3-5 recommended)
<examples>
<example1>
Input: [Sample input]
Output: [Expected output format and content]
</example1>
<example2>
Input: [Different sample input]
Output: [Expected output for this input]
</example2>
<example3>
Input: [Another diverse sample input]
Output: [Expected output for this input]
</example3>
[Add 1-2 more examples if needed, ensuring they cover potential edge cases and challenges]
</examples>

## 5. Role Definition (Optional)
system="You are [define specific role/expertise for the LLM to assume]."

Example roles:
- "a seasoned data scientist at a Fortune 500 company"
- "the General Counsel of a multinational tech corporation"
- "a creative copywriter specializing in B2B marketing"

## 6. Chain of Thought (Optional)
Choose one of the following options based on task complexity:
a) Basic: Include "Think step-by-step" in your prompt.
b) Guided: Outline specific steps for Claude to follow in its thinking process.
c) Structured: Use XML tags to separate reasoning from the final answer:
<thinking>
[Step-by-step reasoning process]
</thinking>
<answer>
[Final response based on the reasoning]
</answer>

## 7. Output Format
Provide your response in the following format:
<output>
[Specify the desired output structure, using placeholder text or nested XML tags as needed]
</output>

## 8. Response Prefill (Optional)
To guide Claude's output (e.g., for JSON formatting or character consistency), prefill the start of the response:
Assistant: {  # Forces Claude to skip preamble and output JSON directly

## 9. Follow-up Tasks (Optional)
After completing the primary task:
1. [Specify any follow-up analyses or questions]
2. [For complex tasks, outline the next steps in the prompt chain]

---

Notes for effective use:
- The golden rule of clear prompting: Test this prompt with a colleague who has minimal context on the task. If they're confused, Claude likely will be too.
- For complex tasks, consider chaining prompts (e.g., Research → Outline → Draft → Edit → Format).
- When using multiple documents, structure them with clear, nested XML tags:
  <documents>
    <document index="1">
      <source>document1.pdf</source>
      <document_content>
        [Content of document 1]
      </document_content>
    </document>
    [Repeat for additional documents]
  </documents>
- For tasks involving long documents, ask Claude to quote relevant parts before analysis.
- Experiment with different roles and prefilling techniques to optimize performance for your specific use case.
- Try these techniques in order from most broadly effective (clear instructions, examples) to more specialized (chain of thought, prefilling).

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------

